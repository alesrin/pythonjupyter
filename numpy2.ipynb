{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones matemáticas y trigonométricas: Raíz cuadrada, exponente y logaritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raíz cuadrada: [1. 2. 3.]\n",
      "Datos transformados con raíz cuadrada: [ 1.          3.16227766 10.         31.6227766 ]\n",
      "RMSE: 0.15811388300841903\n",
      "RMSE con Scikit-learn: 0.15811388300841903\n",
      "Exponente: [2.71828183e+00 5.45981500e+01 8.10308393e+03]\n",
      "Probabilidades softmax: [0.65900114 0.24243297 0.09856589]\n",
      "Probabilidades softmax con Scikit-learn: [[0.65900114 0.24243297 0.09856589]]\n",
      "Probabilidades softmax con Spicy: [0.65900114 0.24243297 0.09856589]\n",
      "Logaritmo: [0.         1.38629436 2.19722458]\n",
      "Log Loss calculado manualmente: 0.16425203348601802\n",
      "Log Loss con Scikit-Learn: 0.16425203348601802\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "g = np.array([1, 4, 9])\n",
    "\n",
    "# Raíz cuadrada: Aunque las normas L1 y L2 son más comunes para regularización y normalización, la raíz cuadrada en sí misma puede aparecer en algunos casos de preprocesamiento de datos para reducir la varianza o ajustar la distribución.\n",
    "h = np.sqrt(g)\n",
    "print(\"Raíz cuadrada:\", h)\n",
    "\n",
    "#---------------------------------------------\n",
    "### Ejemplo de aplicación de np.sqrt a transformación de datos sesgados\n",
    "# La raíz cuadrada es una transformación común para datos sesgados, ya que reduce la asimetría y hace que los datos se parezcan más a una distribución normal. Esto puede ser útil para ciertos modelos de Machine Learning que asumen normalidad en los datos. Por ejemplo, si tenemos datos que siguen una distribución exponencial, aplicar la raíz cuadrada puede hacer que se parezcan más a una distribución normal. \n",
    "\n",
    "datos_originales = np.array([1, 10, 100, 1000])\n",
    "transformados = np.sqrt(datos_originales)\n",
    "print(\"Datos transformados con raíz cuadrada:\", transformados)\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "### Ejemplo de aplicación de np.sqrt a evaluación de modelos de Machine Learning (RMSE)\n",
    "\n",
    "\"\"\" El error cuadrático medio (RMSE) es una métrica común para evaluar la precisión de un modelo de Machine Learning, y se calcula de la siguiente manera:\n",
    "1. Se calcula la diferencia entre cada predicción y el valor real.\n",
    "2. Se eleva al cuadrado cada diferencia (para evitar números negativos y dar más peso a los errores grandes).\n",
    "3. Se saca el promedio de todos estos errores cuadrados.\n",
    "4. Se toma la raíz cuadrada para que la métrica vuelva a estar en la misma escala que los datos originales.\"\"\"\n",
    "\n",
    "# Valores reales y predichos\n",
    "y = np.array([3, 5, 2, 7])\n",
    "y_pred = np.array([2.8, 4.9, 2.1, 6.8])\n",
    "\n",
    "# Calcular el error cuadrático (y - y_pred)^2\n",
    "errors = (y - y_pred) ** 2 # Para que todos los errores se sumen de manera positiva (y no se cancelen entre sí), elevamos al cuadrado las diferencias entre las predicciones y los resultados reales.\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE)\n",
    "mse = np.mean(errors) #Sumamos todos los errores cuadrados y luego los dividimos por la cantidad de ejemplos que tenemos\n",
    "\n",
    "# Tomar la raíz cuadrada para obtener RMSE\n",
    "rmse = np.sqrt(mse) #Tomamos la raíz cuadrada del MSE para que la métrica vuelva a estar en la misma escala que los datos originales.\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"RMSE: {rmse}\")\n",
    "#El RMSE es 0.1581, lo que indica el promedio de la magnitud del error en las predicciones del modelo, en la misma unidad que los valores originales. Un RMSE bajo indica que el modelo tiene una buena precisión en sus predicciones.\n",
    "\n",
    "# También se puede calcular el RMSE con la función mean_squared_error de Scikit-learn\n",
    "from sklearn.metrics import root_mean_squared_error  \n",
    "rmse_sklearn = root_mean_squared_error(y, y_pred)  \n",
    "print(\"RMSE con Scikit-learn:\", rmse_sklearn)\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "# Exponente: En modelos de clasificación, softmax convierte salidas de la red neuronal en probabilidades\n",
    "i = np.exp(g)\n",
    "print(\"Exponente:\", i)\n",
    "\n",
    "#---------------------------------------------\n",
    "### Ejemplo de aplicación de np.exp a evaluación de modelos de Machine Learning (RMSE)\n",
    "\n",
    "# PASO 1: Definir los logits (puntuaciones sin procesar del modelo)\n",
    "logits = np.array([2.0, 1.0, 0.1])  \n",
    "# Estos valores representan la confianza del modelo en tres clases diferentes\n",
    "\n",
    "# PASO 2: Aplicar la función exponencial a cada valor\n",
    "exp_values = np.exp(logits)  \n",
    "# Esto convierte los valores en números positivos más grandes, manteniendo la relación entre ellos\n",
    "# Por ejemplo, e^2, e^1, e^0.1 se convierten en [7.389, 2.718, 1.105]\n",
    "\n",
    "# PASO 3: Normalizar dividiendo por la suma total de exponentes\n",
    "probabilities = exp_values / np.sum(exp_values)  \n",
    "# Ahora, cada valor se divide por la suma total, asegurando que las probabilidades sumen 1\n",
    "\n",
    "# PASO 4: Imprimir el resultado\n",
    "print(\"Probabilidades softmax:\", probabilities)  \n",
    "# Esto devuelve algo como: [0.659, 0.242, 0.099], lo que significa:\n",
    "# - La primera clase (Gato) tiene un 65.9% de probabilidad de ser la correcta.\n",
    "# - La segunda clase (Perro) tiene un 24.2%.\n",
    "# - La tercera clase (Conejo) tiene solo un 9.9%.\n",
    "\n",
    "\"\"\"\n",
    "Podemos crear nuestra propia función softmax:\n",
    "def softmax(logits):\n",
    "    \" \" \" \n",
    "    Calcula la función softmax sobre un conjunto de valores (logits).\n",
    "\n",
    "    Args:\n",
    "        logits (array): Array de números que representan puntuaciones sin procesar de un modelo.\n",
    "\n",
    "    Returns:\n",
    "        array: Probabilidades normalizadas que suman 1.\n",
    "    \" \" \" \n",
    "    exp_values = np.exp(logits)  # Aplicamos la función exponencial a cada elemento\n",
    "    return exp_values / np.sum(exp_values)  # Normalizamos dividiendo por la suma total\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Esto también se puede hacer con la función softmax de Scikit-learn\n",
    "from sklearn.utils.extmath import softmax  # Importamos la función softmax de Scikit-learn\n",
    "\n",
    "# Aplicar la función softmax\n",
    "probabilities_sklearn = softmax(logits.reshape(1, -1))\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(\"Probabilidades softmax con Scikit-learn:\", probabilities_sklearn)\n",
    "\n",
    "# O también con la función softmax de scipy\n",
    "from scipy.special import softmax  # Importamos la función softmax de scipy\n",
    "\n",
    "# Definir los logits (valores sin procesar)\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "\n",
    "# Calcular softmax con scipy\n",
    "probabilities = softmax(logits)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Probabilidades softmax con Spicy:\", probabilities)\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "# Logaritmo: El logaritmo natural se usa en Machine Learning y Deep Learning en varias áreas, especialmente en funciones de pérdida, optimización y modelado probabilístico. Cuando entrenamos modelos de clasificación, una métrica común para medir el rendimiento es la pérdida logarítmica (log loss), que usa el logaritmo natural para penalizar predicciones incorrectas. En optimización, el logaritmo natural también se usa en algoritmos de descenso de gradiente para actualizar los pesos de la red neuronal. En modelado probabilístico, el logaritmo natural se usa para convertir productos en sumas, lo que facilita el cálculo de probabilidades.\n",
    "\n",
    "j = np.log(g)\n",
    "print(\"Logaritmo:\", j)\n",
    "\n",
    "#---------------------------------------------\n",
    "### Ejemplo de cálculo manual de Log Loss\n",
    "\n",
    "# 1: Etiquetas reales (1 = gato, 0 = no gato)\n",
    "y_true = np.array([1, 0, 1, 0])\n",
    "\n",
    "# 2: Predicciones del modelo (probabilidad de ser un gato)\n",
    "y_pred = np.array([0.9, 0.2, 0.8, 0.1])  # Valores entre 0 y 1\n",
    "\n",
    "# 3: Cálculo de Log Loss\n",
    "log_loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "\"\"\"\n",
    "def log_loss(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "- Si las predicciones son muy precisas (las probabilidades están cerca de 1 para etiquetas 1 y cerca de 0 para etiquetas 0), la log loss será baja.\n",
    "- Si las predicciones están lejos de las etiquetas reales, la log loss será alta.\n",
    "- Penaliza fuertemente las predicciones erróneas con alta confianza (por ejemplo, predecir 0.99 cuando la etiqueta real es 0).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 4: Imprimir el resultado\n",
    "print(f\"Log Loss calculado manualmente: {log_loss}\")\n",
    "\n",
    "# Esto también se puede hacer con la función log_loss de Scikit-learn\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss_sklearn = log_loss(y_true, y_pred)\n",
    "print(f\"Log Loss con Scikit-Learn: {log_loss_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edades ordenadas: [18 22 25 30 35 40 45 50]\n",
      "Copia ordenada: [1 2 3 5 7 9]\n",
      "Copia ordenada: [1 2 3 5 7 9]\n",
      "Columnas ordenadas: [[5 1 2]\n",
      " [6 3 7]\n",
      " [9 4 8]]\n",
      "Filas ordenadas: [[2 4 9]\n",
      " [1 6 7]\n",
      " [3 5 8]]\n"
     ]
    }
   ],
   "source": [
    "edades = np.array([25, 30, 18, 40, 35, 22, 45, 50])\n",
    "\n",
    "# Ordenar edades de menor a mayor\n",
    "edades_ordenadas = np.sort(edades)\n",
    "print(\"Edades ordenadas:\", edades_ordenadas)\n",
    "\n",
    "# Crear un array 1D desordenado\n",
    "arr_1d = np.array([5, 2, 9, 1, 7, 3])\n",
    "\n",
    "# Ordenar un array 1D (retorna una copia ordenada, el array original no se modifica)\n",
    "arr_sorted = np.sort(arr_1d)\n",
    "print(\"Copia ordenada:\", arr_sorted)\n",
    "\n",
    "\n",
    "# Ordenar un array 1D en su lugar (modifica el array original)\n",
    "arr_1d.sort()\n",
    "print(\"Copia ordenada:\", arr_1d)\n",
    "\n",
    "# Crear un array 2D desordenado\n",
    "arr_2d = np.array([[9, 4, 2],\n",
    "  [6, 1, 7],\n",
    "  [5, 3, 8]])\n",
    "\n",
    "# Ordenar un array 2D por columnas\n",
    "arr_sorted_columns = np.sort(arr_2d, axis=0)\n",
    "print(\"Columnas ordenadas:\", arr_sorted_columns)\n",
    "\n",
    "\n",
    "# Ordenar un array 2D por filas\n",
    "arr_sorted_rows = np.sort(arr_2d, axis=1)\n",
    "print(\"Filas ordenadas:\", arr_sorted_rows)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsquedas y filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "[5 7 9]\n",
      "(array([3, 4, 5]),)\n",
      "Precios filtrados: [ 50 100 150 200]\n",
      "Índices: (array([0, 1, 2, 3]),)\n",
      "Datos filtrados: [30 35 40 45 50 55 60]\n",
      "Índices: (array([1, 2, 2, 2, 3, 3, 3]), array([2, 0, 1, 2, 0, 1, 2]))\n",
      "Calificaciones reemplazadas: [85 90 80 92 80 80 98 89]\n",
      "Notas reemplazadas:\n",
      " [[85 90 80]\n",
      " [92 80 80]\n",
      " [98 89 80]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Buscar el índice del valor mínimo en un array 1D\n",
    "min_index = np.argmin(arr_1d)\n",
    "print(min_index)\n",
    "\n",
    "# 2. Buscar el índice del valor máximo en un array 1D\n",
    "max_index = np.argmax(arr_1d)\n",
    "print(max_index)\n",
    "\n",
    "# 3. Buscar valores que cumplan ciertos criterios en un array\n",
    "arr_filtered = arr_1d[arr_1d > 3]\n",
    "print(arr_filtered)\n",
    "\n",
    "# 4. Encontrar los índices de los elementos que cumplen ciertos criterios en un array\n",
    "indices = np.where(arr_1d > 3)\n",
    "print(indices)\n",
    "\n",
    "# 5. Filtrar datos de un array 1D\n",
    "precios = np.array([50, 100, 150, 200, 250, 300, 350, 400])\n",
    "\n",
    "# Filtrar precios menores o iguales a 200\n",
    "precios_filtrados = precios[precios <= 200]\n",
    "print(\"Precios filtrados:\", precios_filtrados)\n",
    "\n",
    "# 6. Encontrar los índices de los elementos que cumplen ciertos criterios en un array 1D\n",
    "indices = np.where(precios <= 200)\n",
    "print(\"Índices:\", indices)\n",
    "\n",
    "# 7. Filtrar datos de un array 2D\n",
    "datos = np.array([[5, 10, 15],\n",
    "  [20, 25, 30],\n",
    "  [35, 40, 45],\n",
    "  [50, 55, 60]])\n",
    "\n",
    "# Filtrar datos mayores a 25\n",
    "datos_filtrados = datos[datos > 25]\n",
    "print(\"Datos filtrados:\", datos_filtrados)\n",
    "\n",
    "# 8. Encontrar los índices de los elementos que cumplen ciertos criterios en un array 2D\n",
    "indices = np.where(datos > 25)\n",
    "print(\"Índices:\", indices)\n",
    "\n",
    "# 9. Reemplazar valores en un array 1D\n",
    "calificaciones = np.array([85, 90, 78, 92, 76, 65, 98, 89])\n",
    "\n",
    "# Reemplazar calificaciones menores a 80 por 80\n",
    "calificaciones[calificaciones < 80] = 80\n",
    "print(\"Calificaciones reemplazadas:\", calificaciones)\n",
    "\n",
    "# 10. Reemplazar valores en un array 2D\n",
    "notas = np.array([[85, 90, 78],\n",
    "  [92, 76, 65],\n",
    "  [98, 89, 80]])\n",
    "\n",
    "# Reemplazar notas menores a 80 por 80\n",
    "notas[notas < 80] = 80\n",
    "print(\"Notas reemplazadas:\\n\", notas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFUNCS\n",
    "\n",
    "Las funciones universales (ufunc) son funciones que operan sobre arrays de NumPy elemento\n",
    "por elemento, de manera similar a las funciones matemáticas de Python.\n",
    "\n",
    "Las funciones universales de NumPy incluyen operaciones matemáticas simples, como suma,\n",
    "resta, multiplicación y división, y funciones trigonométricas, exponenciales y logarítmicas, entre\n",
    "otras.\n",
    "\n",
    "Las funciones universales de NumPy son mucho más rápidas que las funciones de Python\n",
    "equivalentes, ya que están implementadas en C.\n",
    "\n",
    "Estas funciones son altamente eficientes y se implementan en lenguajes de bajo nivel como C o\n",
    "Fortran para mejorar su rendimiento.\n",
    "\n",
    "Las ufuncs son útiles para realizar operaciones matemáticas y lógicas en arrays sin necesidad de\n",
    "utilizar bucles explícitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma: [ 6  8 10 12]\n",
      "Resta: [-4 -4 -4 -4]\n",
      "Producto: [ 5 12 21 32]\n",
      "Cociente: [0.2        0.33333333 0.42857143 0.5       ]\n",
      "Redondeo: [1. 2. 4. 4.]\n",
      "Piso: [1. 2. 3. 4.]\n",
      "Techo: [2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Crear dos arrays de ejemplo\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([5, 6, 7, 8])\n",
    "\n",
    "# Operaciones aritméticas básicas (elemento a elemento)\n",
    "sum_result = np.add(arr1, arr2)\n",
    "print(\"Suma:\", sum_result)\n",
    "\n",
    "diff_result = np.subtract(arr1, arr2)\n",
    "print(\"Resta:\", diff_result)\n",
    "\n",
    "product_result = np.multiply(arr1, arr2)\n",
    "print(\"Producto:\", product_result)\n",
    "\n",
    "quotient_result = np.divide(arr1, arr2)\n",
    "print(\"Cociente:\", quotient_result)\n",
    "\n",
    "# Funciones de redondeo\n",
    "arr4 = np.array([1.2, 2.5, 3.7, 4.1])\n",
    "round_result = np.round(arr4) #Redondea al número entero más cercano.\n",
    "print(\"Redondeo:\", round_result)\n",
    "\n",
    "floor_result = np.floor(arr4)\n",
    "print(\"Piso:\", floor_result) #Siempre redondea al número entero más bajo (sin importar los decimales).\n",
    "\n",
    "ceil_result = np.ceil(arr4) #Siempre redondea al número entero más alto (sin importar los decimales).\n",
    "print(\"Techo:\", ceil_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma sin usar ufuncs: [ 6.  8. 10. 12.]\n",
      "Suma usando ufuncs: [ 6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "# Crear dos arrays de ejemplo\n",
    "arr1 = np.array([1, 2, 3, 4])  # Se crea un array de NumPy llamado 'arr1' con los valores [1, 2, 3, 4]\n",
    "arr2 = np.array([5, 6, 7, 8])  # Se crea un segundo array de NumPy llamado 'arr2' con los valores [5, 6, 7, 8]\n",
    "\n",
    "# Suma (elemento a elemento) sin usar ufuncs\n",
    "sum_result = np.zeros(len(arr1))  # Se crea un array 'sum_result' lleno de ceros con la misma longitud que 'arr1'\n",
    "for i in range(len(arr1)):  # Iniciamos un bucle que va desde 0 hasta la longitud de 'arr1' (en este caso 4)\n",
    "    sum_result[i] = arr1[i] + arr2[i]  # En cada iteración, sumamos los elementos en la misma posición de 'arr1' y 'arr2'\n",
    "print(\"Suma sin usar ufuncs:\", sum_result)  # Imprime el resultado de la suma sin usar ufuncs\n",
    "\n",
    "# Suma (elemento a elemento) usando ufuncs\n",
    "sum_result = np.add(arr1, arr2)  # Utiliza la función 'np.add' para sumar los dos arrays de manera eficiente\n",
    "print(\"Suma usando ufuncs:\", sum_result)  # Imprime el resultado de la suma usando ufuncs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla recopilatorio\n",
    "\n",
    "| Nombre de la función | Descripción | Argumentos | Etapa del flujo del proyecto de IA en la que se usa | Ejemplo de uso |\n",
    "|----------------------|-------------|------------|-----------------------------------|----------------|\n",
    "| `np.array()` | Crea un array de NumPy a partir de listas o tuplas. | `obj`: lista o tupla | Preprocesamiento de datos, Manipulación de datos | `arr = np.array([1, 2, 3])` |\n",
    "| `np.mean()` | Calcula el promedio (media) de los elementos de un array. | `a`: array, `axis`: (opcional) especifica el eje sobre el que calcular la media | Preprocesamiento, Evaluación de modelo | `mean_value = np.mean([1, 2, 3, 4])` |\n",
    "| `np.std()` | Calcula la desviación estándar de los elementos de un array. | `a`: array, `axis`: (opcional) especifica el eje sobre el que calcular la desviación | Preprocesamiento, Evaluación de modelo | `std_value = np.std([1, 2, 3, 4])` |\n",
    "| `np.min()` | Devuelve el valor mínimo de un array. | `a`: array, `axis`: (opcional) especifica el eje sobre el que calcular el mínimo | Preprocesamiento, Evaluación de modelo | `min_value = np.min([1, 2, 3, 4])` |\n",
    "| `np.max()` | Devuelve el valor máximo de un array. | `a`: array, `axis`: (opcional) especifica el eje sobre el que calcular el máximo | Preprocesamiento, Evaluación de modelo | `max_value = np.max([1, 2, 3, 4])` |\n",
    "| `np.sqrt()` | Calcula la raíz cuadrada de cada elemento de un array. | `a`: array | Transformación de datos, Optimización | `sqrt_value = np.sqrt([1, 4, 9])` |\n",
    "| `np.exp()` | Calcula la función exponencial de cada elemento de un array. | `a`: array | Transformación de datos | `exp_value = np.exp([1, 2, 3])` |\n",
    "| `np.log()` | Calcula el logaritmo natural (base e) de cada elemento de un array. | `a`: array | Transformación de datos, Preprocesamiento | `log_value = np.log([1, 2, 3])` |\n",
    "| `np.dot()` | Realiza el producto punto de dos arrays. | `a`: array, `b`: array | Modelado, Cálculo de predicciones | `dot_value = np.dot([1, 2], [3, 4])` |\n",
    "| `np.random.rand()` | Genera un array de números aleatorios entre 0 y 1 con la forma especificada. | `shape`: tupla con las dimensiones deseadas | Generación de datos, Inicialización de parámetros | `random_values = np.random.rand(2, 3)` |\n",
    "| `np.random.randn()` | Genera un array de números aleatorios con distribución normal estándar (media 0, desviación 1). | `shape`: tupla con las dimensiones deseadas | Generación de datos, Inicialización de parámetros | `randn_values = np.random.randn(2, 3)` |\n",
    "| `np.reshape()` | Cambia la forma de un array sin cambiar sus datos. | `a`: array, `newshape`: nueva forma | Preprocesamiento, Transformación de datos | `reshaped_array = np.reshape([1, 2, 3, 4], (2, 2))` |\n",
    "| `np.concatenate()` | Une dos o más arrays a lo largo de un eje especificado. | `a`: array, `b`: array, `axis`: (opcional) eje sobre el que concatenar | Preprocesamiento, Combinación de datos | `concatenated = np.concatenate([arr1, arr2], axis=0)` |\n",
    "| `np.linalg.inv()` | Calcula la matriz inversa de una matriz cuadrada. | `a`: matriz cuadrada | Modelado, Cálculos matemáticos | `inverse_matrix = np.linalg.inv([[1, 2], [3, 4]])` |\n",
    "| `np.linalg.eig()` | Calcula los valores propios y vectores propios de una matriz. | `a`: matriz cuadrada | Modelado, Cálculos matemáticos | `eigvals, eigvecs = np.linalg.eig([[1, 2], [3, 4]])` |\n",
    "| `np.where()` | Devuelve elementos de un array si se cumple una condición, y otro valor si no se cumple. | `condition`: condición booleana, `x`: valor si la condición es verdadera, `y`: valor si es falsa | Preprocesamiento, Manipulación de datos | `result = np.where([True, False, True], [1, 2, 3], [4, 5, 6])` |\n",
    "| `np.argmax()` | Devuelve el índice del valor máximo en un array. | `a`: array | Evaluación de modelo, Optimización | `index_max = np.argmax([1, 2, 3])` |\n",
    "| `np.argmin()` | Devuelve el índice del valor mínimo en un array. | `a`: array | Evaluación de modelo, Optimización | `index_min = np.argmin([1, 2, 3])` |\n",
    "| `np.add()` | Suma dos arrays elemento por elemento. | `x`: array, `y`: array | Manipulación de datos, Cálculos | `result = np.add([1, 2], [3, 4])` |\n",
    "| `np.subtract()` | Resta dos arrays elemento por elemento. | `x`: array, `y`: array | Manipulación de datos, Cálculos | `result = np.subtract([1, 2], [3, 4])` |\n",
    "| `np.multiply()` | Multiplica dos arrays elemento por elemento. | `x`: array, `y`: array | Manipulación de datos, Cálculos | `result = np.multiply([1, 2], [3, 4])` |\n",
    "| `np.divide()` | Divide dos arrays elemento por elemento. | `x`: array, `y`: array | Manipulación de datos, Cálculos | `result = np.divide([1, 2], [3, 4])` |\n",
    "| `np.power()` | Eleva un array a una potencia específica. | `x`: array, `y`: valor de la potencia | Manipulación de datos, Transformación | `result = np.power([1, 2], 3)` |\n",
    "| `np.sin()` | Calcula el seno de cada elemento de un array. | `a`: array | Transformación de datos, Funciones trigonométricas | `sin_values = np.sin([0, np.pi/2])` |\n",
    "| `np.cos()` | Calcula el coseno de cada elemento de un array. | `a`: array | Transformación de datos, Funciones trigonométricas | `cos_values = np.cos([0, np.pi/2])` |\n",
    "| `np.tan()` | Calcula la tangente de cada elemento de un array. | `a`: array | Transformación de datos, Funciones trigonométricas | `tan_values = np.tan([0, np.pi/4])` |\n",
    "| `np.arcsin()` | Calcula el arco seno de cada elemento de un array. | `a`: array | Transformación de datos, Funciones trigonométricas | `arcsin_values = np.arcsin([0, 1])` |\n",
    "| `np.arccos()` | Calcula el arco coseno de cada elemento de un array. | `a`: array | Transformación de datos, Funciones trigonométricas | `arccos_values = np.arccos([0, 1])` |\n",
    "| `np.arctan()` | Calcula el arco tangente de cada elemento de un array. | `a`: array | Transformación de datos, Funciones trigonométricas | `arctan_values = np.arctan([0, 1])` |\n",
    "| `np.abs()` | Devuelve el valor absoluto de cada elemento de un array. | `a`: array | Preprocesamiento, Evaluación de modelo | `abs_values = np.abs([-1, -2, 3])` |\n",
    "| `np.sign()` | Devuelve el signo de cada elemento de un array (-1, 0 o 1). | `a`: array | Preprocesamiento, Evaluación de modelo | `sign_values = np.sign([-1, 0, 1])` |\n",
    "\n",
    "\n",
    "\n",
    "Se debe tener en cuenta que las etapas técnicas del flujo de un proyecto de IA son las siguientes\n",
    "\n",
    "#### Preparación de datos\n",
    "\n",
    "Esta etapa involucra la recolección, limpieza y transformación de datos para prepararlos para el análisis.\n",
    "\n",
    "#### Análisis exploratorio de datos (EDA)\n",
    "\n",
    "En esta fase se analizan los datos para obtener una comprensión preliminar de sus características y relaciones.\n",
    "\n",
    "#### Transformación de datos\n",
    "\n",
    "En esta etapa se realizan transformaciones en los datos, como normalización, escalado o cambios en su estructura.\n",
    "\n",
    "#### Entrenamiento de modelo\n",
    "\n",
    "Durante esta etapa se entrenan los modelos de IA con los datos, ajustando sus parámetros.\n",
    "\n",
    "#### Evaluación de modelo\n",
    "\n",
    "Aquí se evalúa el rendimiento de los modelos entrenados utilizando métricas como el error cuadrático medio (RMSE), precisión, etc.\n",
    "\n",
    "#### Optimización\n",
    "\n",
    "Fase en la que se afinan los modelos y se prueban diversas estrategias para mejorar su rendimiento.\n",
    "\n",
    "#### Predicción/Inferencia\n",
    "\n",
    "Después de entrenar y optimizar el modelo, se utiliza para hacer predicciones sobre nuevos datos.\n",
    "\n",
    "#### Despliegue\n",
    "\n",
    "Una vez que el modelo está entrenado y evaluado, se implementa en un entorno de producción para su uso en tiempo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer datos CSV\n",
    "\n",
    "→ Puedes descargar los CSV de ejemplo que utilizaremos en el máster desde aquí:  `https://www.ibm.com/docs/es/scis?topic=samples-sample-csv-files`\n",
    "\n",
    "## Propiedades importantes de `numpy.genfromtxt()` para leer CSV\n",
    "\n",
    "### Control de delimitadores y formato de datos\n",
    "- `delimiter=','` → Define el separador de los valores (`,`, `;`, `\\t`, etc.).\n",
    "- `dtype=float` → Define el tipo de datos a leer (`float`, `int`, `str`, etc.).\n",
    "- `encoding='utf-8'` → Especifica la codificación del archivo (importante para caracteres especiales).\n",
    "\n",
    "### Manejo de cabeceras y filas\n",
    "- `skip_header=1` → Omite la primera fila (útil si el CSV tiene encabezados).\n",
    "- `skip_footer=2` → Omite las últimas 2 filas.\n",
    "- `max_rows=100` → Lee solo las primeras 100 filas.\n",
    "\n",
    "### Manejo de valores vacíos o incorrectos\n",
    "- `filling_values=0` → Reemplaza valores faltantes con `0`.\n",
    "- `missing_values='?'` → Indica qué valores deben tratarse como vacíos (`?`, `NULL`, etc.).\n",
    "- `usemask=True` → Devuelve una matriz enmascarada para identificar valores faltantes.\n",
    "\n",
    "### Control de comentarios y saltos de línea\n",
    "- `comments='#'` → Ignora líneas que comiencen con `#`.\n",
    "- `newline='\\n'` → Define el carácter de salto de línea.\n",
    "\n",
    "### Carga de columnas específicas\n",
    "- `usecols=(0, 2, 4)` → Carga solo las columnas 0, 2 y 4.\n",
    "\n",
    "### Depuración y validación de datos\n",
    "- `invalid_raise=False` → Evita que el programa falle si hay errores en los datos.\n",
    "- `names=True` → Usa la primera fila como nombres de columna (requiere `dtype=None`).\n",
    "\n",
    "## ¿Por qué utilizaremos Pandas en vez de Numpy?\n",
    "\n",
    "- Manejo automático de encabezados → Detecta y usa los nombres de columnas sin necesidad de skip_header.\n",
    "- Soporte para datos mixtos → Puede manejar números, texto y valores NaN sin problemas.\n",
    "- Funciones avanzadas de limpieza → Métodos como dropna(), fillna(), astype(), etc.\n",
    "- Mayor eficiencia en archivos grandes → pandas.read_csv() está optimizado para leer archivos más grandes sin perder rendimiento.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 1: ['Street Lighting' 'Pedestrian Lighting' 'Traffic Signal Poles' 'Controls'\n",
      " 'Downlights' 'Retrofit Downlights' 'Ambient' 'Bulbs' 'Controllers'\n",
      " 'Enclosures' 'High Voltage Electrical' 'Lenses' 'Luminaire' 'Mechanicals'\n",
      " 'Primary Chassis' 'Primary Foundation' 'Secondary Chassis'\n",
      " 'Public Sector' 'Commercial' 'Alliance' 'Helm' 'Flatbush Avenue'\n",
      " 'Bishops Crook' 'City Light' 'LED Type E' 'All' 'Cobra Head' 'Stad'\n",
      " 'Fulton' 'Flushing Meadows' 'World’s Fair' 'Round Top Head' 'All'\n",
      " 'Type M–2 Traffic Signal Pole' 'Alliance Traffic Signal Pole' 'All'\n",
      " 'Ventura' 'Northridge ' 'Miramar ' 'Tulare' 'Alameda' 'Alpine'\n",
      " 'Imperial ' 'Sunset ' 'Riverside' 'Buccaneer ' 'Santa Cruz ' 'Stinson '\n",
      " 'Rural' 'City' 'Special application' 'Traffic' 'Bulbs' 'Controllers'\n",
      " 'Enclosures' 'High Voltage Electrical' 'Lenses' 'Luminaire' 'Mechanicals'\n",
      " 'Primary Chassis' 'Primary Foundation' 'Secondary Chassis']\n"
     ]
    }
   ],
   "source": [
    "# Asumiendo que el archivo 'data.csv' contiene datos numéricos separados por comas\n",
    "\n",
    "data = np.genfromtxt('Catalog_v2.csv', delimiter=',', skip_header=1, filling_values=0, dtype=str)\n",
    "\n",
    "column_1 = data[:, 0]\n",
    "column_2 = data[:, 1]\n",
    "column_3 = data[:, 2]\n",
    "\n",
    "print(\"Columna 1:\", column_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "### ¿Qué diferencia hay entre un CSV, un Dataset y un Dataframe?\n",
    "\n",
    "| **Concepto**  | **Formato**  | **Dónde se usa**  | **Características** |\n",
    "|--------------|------------|------------------|------------------|\n",
    "| **CSV** | Archivo de texto (.csv) | Para almacenar y transferir datos | Datos separados por comas, sin estructura avanzada. |\n",
    "| **Dataset** | Puede ser CSV, JSON, SQL, etc. | Cualquier colección de datos | Puede estar en bases de datos, archivos, APIs. |\n",
    "| **DataFrame** | Objeto de pandas en Python | Para análisis y manipulación de datos | Soporta índices, tipos de datos y operaciones avanzadas. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ver un ejemplo con pandas\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('Catalog_v2.csv')\n",
    "\n",
    "# Mostrar las primeras 5 filas\n",
    "print(\"5 primeras filas:\", df.head())\n",
    "\n",
    "# Mostrar las últimas 5 filas con formato de tabla (tabulate)\n",
    "print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "#Eliminar espacios vacios y mostrar columnas\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"Todas las columnas:\", df.columns)  \n",
    "\n",
    "#Acceder a una columna por su nombre\n",
    "print(\"Columna code:\", df['code']) \n",
    "\n",
    "#Acceder a una columna por su index\n",
    "print(\"Tercera columna:\", df.iloc[:, 2])  # Accede a la tercera columna (índice 2)\n",
    "\n",
    "#Acceder a una fila por su index\n",
    "print(\"Tercera fila:\", df.iloc[2, :])  # Accede a la tercera fila (índice 2)\n",
    "\n",
    "# Ajustar pandas para mostrar todas las filas y columnas\n",
    "pd.set_option('display.max_rows', None)  # Muestra todas las filas\n",
    "pd.set_option('display.max_columns', None)  # Muestra todas las columnas\n",
    "\n",
    "# Imprimir el DataFrame completo\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Nombre de la función | Descripción | Argumentos | Ejemplo de uso | Principales usos |\n",
    "|----------------------|-------------|------------|----------------|------------------|\n",
    "| `pd.read_csv()` | Lee un archivo CSV y lo convierte en un DataFrame de pandas. | `'filepath_or_buffer'`: ruta del archivo, `'delimiter'`: separador, `'header'`: fila de encabezado. | `df = pd.read_csv('datos.csv')` | Carga de datos en proyectos de IA. |\n",
    "| `pd.DataFrame()` | Crea un DataFrame desde listas, diccionarios o arrays. | `data`: datos a convertir, `columns`: nombres de columnas. | `df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})` | Manipulación y análisis de datos. |\n",
    "| `df.head()` | Muestra las primeras `n` filas del DataFrame. | `n`: número de filas a mostrar (por defecto 5). | `df.head(3)` | Inspección rápida de datos. |\n",
    "| `df.tail()` | Muestra las últimas `n` filas del DataFrame. | `n`: número de filas a mostrar (por defecto 5). | `df.tail(3)` | Revisión de las últimas filas. |\n",
    "| `df.info()` | Muestra información sobre las columnas, tipos de datos y valores nulos. | Ninguno. | `df.info()` | Diagnóstico del DataFrame antes del preprocesamiento. |\n",
    "| `df.describe()` | Proporciona estadísticas descriptivas de las columnas numéricas. | `include`: especifica si se incluyen datos categóricos. | `df.describe()` | Exploración de datos numéricos. |\n",
    "| `df.columns` | Muestra el nombre de las columnas del DataFrame. | Ninguno. | `print(df.columns)` | Identificación de nombres de columnas. |\n",
    "| `df.dtypes` | Muestra los tipos de datos de cada columna. | Ninguno. | `df.dtypes` | Verificación de tipos de datos en la preparación de datos. |\n",
    "| `df.shape` | Retorna el número de filas y columnas del DataFrame. | Ninguno. | `df.shape` | Conocer la dimensión de los datos. |\n",
    "| `df.isnull()` | Devuelve un DataFrame con valores booleanos indicando valores nulos. | Ninguno. | `df.isnull().sum()` | Detección de valores nulos en los datos. |\n",
    "| `df.dropna()` | Elimina las filas o columnas con valores nulos. | `axis=0`: elimina filas, `axis=1`: elimina columnas. | `df.dropna()` | Limpieza de datos. |\n",
    "| `df.fillna()` | Rellena valores nulos con un valor específico o un método. | `value`: valor a usar, `method='ffill'` o `'bfill'` para rellenar con valores anteriores o siguientes. | `df.fillna(0)` | Tratamiento de valores nulos. |\n",
    "| `df.duplicated()` | Devuelve un booleano indicando filas duplicadas. | `subset`: columnas a considerar. | `df[df.duplicated()]` | Identificación de duplicados. |\n",
    "| `df.drop_duplicates()` | Elimina filas duplicadas. | `subset`: columnas a considerar, `keep='first'`: conserva la primera ocurrencia. | `df.drop_duplicates()` | Limpieza de datos duplicados. |\n",
    "| `df.sort_values()` | Ordena el DataFrame por una columna. | `by`: columna a ordenar, `ascending`: `True` o `False`. | `df.sort_values(by='edad', ascending=False)` | Ordenación de datos. |\n",
    "| `df.groupby()` | Agrupa datos según una columna y aplica funciones agregadas. | `by`: columna de agrupación. | `df.groupby('categoria').mean()` | Agrupación y resumen de datos. |\n",
    "| `df.merge()` | Une dos DataFrames basado en una clave común. | `on`: columna común, `how`: `'inner'`, `'outer'`, `'left'`, `'right'`. | `df1.merge(df2, on='id', how='left')` | Combinación de conjuntos de datos. |\n",
    "| `df.pivot_table()` | Crea una tabla dinámica con funciones agregadas. | `values`, `index`, `columns`, `aggfunc`. | `df.pivot_table(values='ventas', index='mes', aggfunc='sum')` | Análisis de datos agregados. |\n",
    "| `df.apply()` | Aplica una función a cada fila o columna. | `func`: función a aplicar, `axis=0` para columnas o `axis=1` para filas. | `df['columna'].apply(np.sqrt)` | Transformaciones personalizadas de datos. |\n",
    "| `df['columna'].map()` | Aplica una función a cada elemento de una serie. | `func`: función a aplicar. | `df['nombre'] = df['nombre'].map(str.upper)` | Transformación de valores en una columna. |\n",
    "| `df['columna'].astype()` | Convierte el tipo de datos de una columna. | `dtype`: tipo de dato deseado. | `df['edad'] = df['edad'].astype(int)` | Conversión de tipos de datos. |\n",
    "| `df.to_csv()` | Guarda el DataFrame en un archivo CSV. | `path_or_buf`: nombre del archivo, `index=False` para no guardar índices. | `df.to_csv('salida.csv', index=False)` | Exportación de datos. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo práctico Numpy y Pandas\n",
    "\n",
    "1. Leer el archivo CSV y convertirlo en un DataFrame pd.DataFrame\n",
    "2. Seleccionar una columna del DataFrame y convertirla en un np.array\n",
    "3. Aplicar operaciones a la columna utilizando numpy\n",
    "4. Añadir los resultados como una nueva columna en el DataFrame\n",
    "5. Guardar el DataFrame actualizado en un nuevo CSV (opcional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Leer el CSV y convertirlo en un DataFrame\n",
    "df = pd.read_csv(\"Product_v6.csv\")\n",
    "print(\"Todas las columnas:\", df.columns)  # Mostrar todas las columnas\n",
    "\n",
    "# 2️. Seleccionar una columna (ejemplo: 'value') y convertirla en un array de NumPy\n",
    "array_np = np.array(df[\"value\"])\n",
    "\n",
    "# 3️. Aplicar una operación con NumPy (ejemplo: raíz cuadrada)\n",
    "resultado_np = np.sqrt(array_np)\n",
    "\n",
    "# 4️. Añadir los resultados como una nueva columna en el DataFrame\n",
    "df[\"raiz_cuadrada\"] = resultado_np\n",
    "\n",
    "# 5️. Guardar el DataFrame actualizado en un nuevo CSV (opcional)\n",
    "df.to_csv(\"datos_modificados.csv\", index=False)\n",
    "\n",
    "# Ver el DataFrame actualizado\n",
    "print(df.head())\n",
    "\n",
    "# EJEMPLO FILTRAR UNA COLUMNA ANTES DE OPERAR: Leer el CSV y convertirlo en un DataFrame\n",
    "df = pd.read_csv(\"Product_v6.csv\")\n",
    "\n",
    "# 2️. Filtrar filas donde la columna 'Categoría' sea 'A'\n",
    "df.loc[df['value'] > 1000, 'value'] *= 2 #df.loc[condición, \"nombre_columna\"]\n",
    "\n",
    "# 3️. Mostrar el DataFrame actualizado\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
